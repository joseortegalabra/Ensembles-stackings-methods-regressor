{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "72f0f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ac8fa",
   "metadata": {},
   "source": [
    "### -1. Root repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca988bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  D:\\Github-mi-repo\\Discovery-ensembles-stackings-methods\\discovery\n",
      "after:  D:\\Github-mi-repo\\Discovery-ensembles-stackings-methods\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# get actual path\n",
    "actual_path = os.path.abspath(os.getcwd())\n",
    "\n",
    "# divide each folder in the path in a list\n",
    "# delete the last element to get the root path of the local folder\n",
    "list_root_path = actual_path.split('\\\\')[:-1]\n",
    "\n",
    "# join the list in a string with the root\n",
    "root_path = '\\\\'.join(list_root_path)\n",
    "\n",
    "# pararme en el root obtenido\n",
    "os.chdir(root_path)\n",
    "\n",
    "print('before: ', actual_path)\n",
    "print('after: ', root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754ed65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de173da",
   "metadata": {},
   "source": [
    "# 1. Data Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375600a",
   "metadata": {},
   "source": [
    "#### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0fd9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters my example\n",
    "N_SAMPLES = 1000\n",
    "N_FEATURES = 20\n",
    "N_INFORMATIVE = 15\n",
    "N_REDUNDANT = 5 # for classification\n",
    "NOISE = 0.1 # for regression\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797154ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters save file\n",
    "path_data_folder = 'data'\n",
    "path_data_example = 'example1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67857970",
   "metadata": {},
   "source": [
    "#### GENERATE DATA X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a5d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_regression(n_samples, n_features, n_informative, noise, random_state):\n",
    "    \n",
    "    # generate data\n",
    "    X, y = make_regression(n_samples=n_samples, \n",
    "                           n_features=n_features, \n",
    "                           n_informative=n_informative, \n",
    "                           noise=noise, \n",
    "                           random_state=random_state)\n",
    "    \n",
    "    # save in a dataframe X\n",
    "    columns_name = ['feature_' + str(x + 1) for x in range(n_features)]\n",
    "    X = pd.DataFrame(X, columns = columns_name)\n",
    "    \n",
    "    # save in a dataframe y\n",
    "    target_name = ['target']\n",
    "    y = pd.DataFrame(y, columns = target_name)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3512ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y = get_dataset_regression(n_samples = N_SAMPLES, \n",
    "                                        n_features = N_FEATURES, \n",
    "                                        n_informative = N_INFORMATIVE, \n",
    "                                        noise = NOISE, \n",
    "                                        random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5379d",
   "metadata": {},
   "source": [
    "#### SPLIT TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38dd9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_X, data_y, test_size = 0.2, random_state = 42, shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a7ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e582f33c",
   "metadata": {},
   "source": [
    "#### SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05867bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path folder where to save\n",
    "path_save = path_data_folder + '/' + path_data_example\n",
    "\n",
    "# save \n",
    "X_train.to_csv(path_save + '/' + 'X_train.csv')\n",
    "y_train.to_csv(path_save + '/' + 'y_train.csv')\n",
    "X_test.to_csv(path_save + '/' + 'X_test.csv')\n",
    "y_test.to_csv(path_save + '/' + 'y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84982090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ddcd09e",
   "metadata": {},
   "source": [
    "# 2. Data Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bde70f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the same of data 1 but has different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ec44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c558ba6a",
   "metadata": {},
   "source": [
    "# 3. Data Example 3\n",
    "- Dataset diamonds (tensorflow)\n",
    "\n",
    "- Its the same of previous data examples, there is a function data generate the data X and data y (this step is the only difference), then divide in train/test and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eae93e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47ef735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_diamonds():\n",
    "    \n",
    "    # load data\n",
    "    dataset_diamonds_tf = tfds.load('diamonds', split = 'train')\n",
    "    dataset_diamonds_tf = tfds.as_dataframe(dataset_diamonds_tf)\n",
    "    \n",
    "    # define list features and target\n",
    "    target = 'price'\n",
    "    features = list(set(list(dataset_diamonds_tf.columns)) - set([target]))\n",
    "    \n",
    "    # get data X and y\n",
    "    X = dataset_diamonds_tf[features]\n",
    "    y = dataset_diamonds_tf[[target]]\n",
    "\n",
    "    # print shape\n",
    "    print('Shape X: ', X.shape)\n",
    "    print('Shape y: ', y.shape)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666d0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b48065f",
   "metadata": {},
   "source": [
    "### 4. Data Example 4\n",
    "- This dataset is different because is downloaded from Kaggle, so in the folder of example 4 are the raw data downloaded direcly from kaggle. \n",
    "- Source: https://www.kaggle.com/datasets/dansbecker/melbourne-housing-snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a057ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH parameters save file\n",
    "path_data_folder = 'data'\n",
    "path_data_example = 'example4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e99e8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "path = path_data_folder + '/' + path_data_example\n",
    "path_raw_data = path + '/melb_data.csv'\n",
    "\n",
    "data = pd.read_csv(path_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ea5a7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there 2 features (priori very important features) that have a lot of nulls, simple solution, I delete this columns\n",
    "columns_to_delete = ['BuildingArea', 'YearBuilt']\n",
    "data = data[list(set(list(data.columns)) - set(columns_to_delete))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "433a4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some null values, so I delete the rows that have nulls\n",
    "data.dropna(inplace = True)\n",
    "data.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "960af773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete features that I consider NO important: \n",
    "# - date is no important, maybe the older sold is cheaper but it need more feature engineer, so, I delete that\n",
    "# - method\n",
    "# - Suburb: there are a lot, it need to be grouped. Need more feature engineer\n",
    "# - Address: already exist longitud and latitud\n",
    "# - SellerG: a lot of people. Need more feature engineer\n",
    "# - CouncilArea: a lot. Need more feature engineer\n",
    "features_no_important = ['Date', 'Method', 'Suburb', 'Address', 'SellerG', 'CouncilArea']\n",
    "data = data[list(set(list(data.columns)) - set(features_no_important))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2a818f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there 2 feature that are categorical -> one hot label encoded\n",
    "list_categorical_features = ['Regionname', 'Type']\n",
    "\n",
    "# separated data numeric - categorical\n",
    "data_numeric = data[list(set(list(data.columns)) - set(list_categorical_features))]\n",
    "data_categorical = data[list_categorical_features]\n",
    "\n",
    "# one hot encoder categorical\n",
    "enc = OneHotEncoder()\n",
    "data_categorical_enc = pd.DataFrame(enc.fit_transform(data_categorical).toarray())\n",
    "\n",
    "# merge dataframe numeric - categorical enc in unique data\n",
    "data = pd.merge(data_numeric, data_categorical_enc, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7c075348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X:  (12211, 22)\n",
      "Shape y:  (12211, 1)\n"
     ]
    }
   ],
   "source": [
    "# separate in X and y\n",
    "target = 'Price'\n",
    "X = data[list(set(list(data.columns)) - set([target]))]\n",
    "y = data[[target]]\n",
    "\n",
    "# print shape\n",
    "print('Shape X: ', X.shape)\n",
    "print('Shape y: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bc9b168b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a047d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
